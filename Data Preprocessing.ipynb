{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1> DATA PREPROCESSING </h1>","metadata":{}},{"cell_type":"markdown","source":"**1. LOADING THE DATASET**","metadata":{}},{"cell_type":"markdown","source":"**We import the dataset from the referenced open-source repository.**","metadata":{}},{"cell_type":"code","source":"# We login to hugging face hub to import the dataset\nfrom huggingface_hub import login\nlogin(new_session=False,\nwrite_permission=True,\ntoken='...',  # Add a valid HuggingFace token in this row to import the dataset\nadd_to_git_credential=True)\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"Salesforce/dialogstudio\", \"TweetSumm\") #The dataset is available in Hugginface ine the Salesforce/dialogstudio repository\ndataset # We show the content of the dataset","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:45.837528Z","iopub.execute_input":"2024-09-10T20:42:45.838212Z","iopub.status.idle":"2024-09-10T20:42:52.759110Z","shell.execute_reply.started":"2024-09-10T20:42:45.838155Z","shell.execute_reply":"2024-09-10T20:42:52.758216Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Token is valid (permission: write).\n\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\nYou might have to re-authenticate when pushing to the Hugging Face Hub.\nRun the following command in your terminal in case you want to set the 'store' credential helper as default.\n\ngit config --global credential.helper store\n\nRead https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\nToken has not been saved to git credential helper.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/18.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5819c84173f246919af12c46fe55254e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/7.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc54fcb69c3f4374a111565439a2d499"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for Salesforce/dialogstudio contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Salesforce/dialogstudio.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"name":"stdout","text":"❤️Attention❤️: Dataset download may take some time. We appreciate your patience!\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['original dialog id', 'new dialog id', 'dialog index', 'original dialog info', 'log', 'prompt'],\n        num_rows: 879\n    })\n    validation: Dataset({\n        features: ['original dialog id', 'new dialog id', 'dialog index', 'original dialog info', 'log', 'prompt'],\n        num_rows: 110\n    })\n    test: Dataset({\n        features: ['original dialog id', 'new dialog id', 'dialog index', 'original dialog info', 'log', 'prompt'],\n        num_rows: 110\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"**2. DATA CLEANING**","metadata":{}},{"cell_type":"markdown","source":"**The data comes from twitter conversation, hence contains informations such as usernames preceded by @, urls, or other contextual information. These elements can be identified by looking at some data samples, and removed.**","metadata":{}},{"cell_type":"code","source":"def clean_data(data):\n    data = re.sub('http://\\S+', '', data) #Deleting urls\n    data = re.sub('https://\\S+', '', data)\n    data = re.sub(r\"@[^\\s]+\", \"\", data) #Deleting twitter usernames preceded by @\n    data = re.sub('_', ' ', data) #Deleting underscores from the text\n    data = re.sub(r\"\\^[^ ]+\", \"\", data) #Deleting names and initials preceded by ^\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:52.761086Z","iopub.execute_input":"2024-09-10T20:42:52.761773Z","iopub.status.idle":"2024-09-10T20:42:52.767102Z","shell.execute_reply.started":"2024-09-10T20:42:52.761728Z","shell.execute_reply":"2024-09-10T20:42:52.766054Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"**3. FORMATTING THE DATASET**","metadata":{}},{"cell_type":"markdown","source":"**The dataset contains many information that will not be used during our training, so the content and the format of the dataset will be adjusted to match our needs.**","metadata":{}},{"cell_type":"code","source":"# We use the python library Pandas to visualise the training and validation datasets\nimport pandas as pd\n\ntraining_data = pd.DataFrame(dataset[\"train\"]) # The training set\nvalidation_data = pd.DataFrame(dataset[\"validation\"]) # The validation set\ntesting_data = pd.DataFrame(dataset[\"test\"]) # The validation set","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:52.768223Z","iopub.execute_input":"2024-09-10T20:42:52.768543Z","iopub.status.idle":"2024-09-10T20:42:52.997984Z","shell.execute_reply.started":"2024-09-10T20:42:52.768486Z","shell.execute_reply":"2024-09-10T20:42:52.997237Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Only the \"log\" column containing the conversation, and the \"original dialog info\" column containing the summaries will be used. So we remove all other columns from the dataset.\n\ntraining_data = training_data.drop(columns=['original dialog id', 'new dialog id','prompt','dialog index']) #Removing unecessary columns from the training data\nvalidation_data = validation_data.drop(columns=['original dialog id', 'new dialog id','prompt','dialog index']) #Removing unecessary columns from the training data\ntesting_data = testing_data.drop(columns=['original dialog id', 'new dialog id','prompt','dialog index']) #Removing unecessary columns from the training data\n\nsummary_column = training_data[\"original dialog info\"]","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.000662Z","iopub.execute_input":"2024-09-10T20:42:53.001354Z","iopub.status.idle":"2024-09-10T20:42:53.016737Z","shell.execute_reply.started":"2024-09-10T20:42:53.001304Z","shell.execute_reply":"2024-09-10T20:42:53.015829Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"\n**The log column contains several data entries, we select only the data entries we will need, \"user utterance\" containing the user message, and \"system response\" containing the agent response, and we group them into a single column to obtain the full dialog between user and agent.**","metadata":{}},{"cell_type":"code","source":"# We create a helper function to update the content of the \"log\" column.\ndef formatting_log(column,data,index):\n    column[index] = data","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.018052Z","iopub.execute_input":"2024-09-10T20:42:53.018390Z","iopub.status.idle":"2024-09-10T20:42:53.027625Z","shell.execute_reply.started":"2024-09-10T20:42:53.018358Z","shell.execute_reply":"2024-09-10T20:42:53.026768Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**We create a function that takes as a parameter a the \"log\" column from the dataset, and updates the content of every row of the column with the text dialog by using the previous helper function.**","metadata":{}},{"cell_type":"code","source":"# Function that will be used to format the dialog column of the training and validation data\nimport re\n\ndef format_column(column):\n    i = 0\n    for row in column:\n        text = \"\"\n        for turn in row: # \n            user = clean_data(turn[\"user utterance\"]) # We select the user utterance\n            agent = clean_data(turn[\"system response\"]) # We select system response\n            text += f\"user:{user}\\nagent:{agent}\\n\" # We concatenate them, and add them to the previous ones if any, which results in the full dialog\n        formatting_log(column, text, i) # We change the content of the column to the text dialog\n        i += 1","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.028836Z","iopub.execute_input":"2024-09-10T20:42:53.029511Z","iopub.status.idle":"2024-09-10T20:42:53.036525Z","shell.execute_reply.started":"2024-09-10T20:42:53.029479Z","shell.execute_reply":"2024-09-10T20:42:53.035594Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Formatting dialog training text using the previous function\ncolumn_log = training_data[\"log\"]\nformat_column(column_log)\nprint(column_log[0])","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.037510Z","iopub.execute_input":"2024-09-10T20:42:53.037792Z","iopub.status.idle":"2024-09-10T20:42:53.188441Z","shell.execute_reply.started":"2024-09-10T20:42:53.037762Z","shell.execute_reply":"2024-09-10T20:42:53.187565Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"user:So neither my iPhone nor my Apple Watch are recording my steps/activity, and Health doesn’t recognise either source anymore for some reason. Any ideas?   please read the above.\nagent: Let’s investigate this together. To start, can you tell us the software versions your iPhone and Apple Watch are running currently?\nuser: My iPhone is on 11.1.2, and my watch is on 4.1.\nagent: Thank you. Have you tried restarting both devices since this started happening?\nuser: I’ve restarted both, also un-paired then re-paired the watch.\nagent: Got it. When did you first notice that the two devices were not talking to each other. Do the two devices communicate through other apps such as Messages?\nuser: Yes, everything seems fine, it’s just Health and activity.\nagent: Let’s move to DM and look into this a bit more. When reaching out in DM, let us know when this first started happening please. For example, did it start after an update or after installing a certain app? \n\n","output_type":"stream"}]},{"cell_type":"code","source":"#Formatting dialog validation text using the previous function\nvalidation_dialog = validation_data[\"log\"]\nformat_column(validation_dialog)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.189593Z","iopub.execute_input":"2024-09-10T20:42:53.189905Z","iopub.status.idle":"2024-09-10T20:42:53.219182Z","shell.execute_reply.started":"2024-09-10T20:42:53.189872Z","shell.execute_reply":"2024-09-10T20:42:53.218213Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#Formatting dialog testing text using the previous function\ntesting_dialog = testing_data[\"log\"]\nformat_column(testing_dialog)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.220422Z","iopub.execute_input":"2024-09-10T20:42:53.220767Z","iopub.status.idle":"2024-09-10T20:42:53.246939Z","shell.execute_reply.started":"2024-09-10T20:42:53.220734Z","shell.execute_reply":"2024-09-10T20:42:53.246033Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#We can now print the first dialog of the validation dataset to make sure that its format is correct.\nprint(validation_dialog[0])","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.251176Z","iopub.execute_input":"2024-09-10T20:42:53.251460Z","iopub.status.idle":"2024-09-10T20:42:53.256315Z","shell.execute_reply.started":"2024-09-10T20:42:53.251430Z","shell.execute_reply":"2024-09-10T20:42:53.255311Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"user: hey, any explanation why the \"Create similar playlist\" function doesn't work anymore for me? MacBook, v1.0.64.399.g4637b02a.\nagent: Hi there, the cavalry's here! Does logging out, restarting your device, and logging back into Spotify help? Keep us in the loop /JI\nuser: no, it didn't :( tried everything but I still can't create the playlist. it's not even greyed out but nothing happens after clicking on it.\nagent: Okay. Can we have you try reinstalling the app? To do so, just follow the steps at \nuser: i tried and it's still the same... moreover, my song history is always empty, so I can't find songs from previous Discover playlists :(\nagent: Does restarting your computer help at all? Also, is the song history you're referring to the History tab on your Play Queue? /MT\nuser: no, I tried that as well and just reinstalled again - didn't help. yes, that's what I mean.\nagent: Could you DM us your account's email address or username? We'll take a look backstage /MT \n\n","output_type":"stream"}]},{"cell_type":"code","source":"# We create a function used to format summary columns of the training and validation datasets\nimport json\n\ndef format_column_summary(column):\n    i=0\n    for row in column:\n        data = column[i]\n        text = json.loads(data)\n        text = text[\"summaries\"][\"abstractive_summaries\"][0]\n        text = \" \".join(text)\n        column[i] = text\n        i+=1","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.257486Z","iopub.execute_input":"2024-09-10T20:42:53.257764Z","iopub.status.idle":"2024-09-10T20:42:53.266809Z","shell.execute_reply.started":"2024-09-10T20:42:53.257734Z","shell.execute_reply":"2024-09-10T20:42:53.265944Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# We use the previously created function to update the content of the \"original dialog info\" column in the training data\nsummary_training = training_data[\"original dialog info\"]\nformat_column_summary(summary_training)\n\n# We print the first row of the training column as a verification\nprint(summary_training[0])","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.267741Z","iopub.execute_input":"2024-09-10T20:42:53.268002Z","iopub.status.idle":"2024-09-10T20:42:53.379292Z","shell.execute_reply.started":"2024-09-10T20:42:53.267973Z","shell.execute_reply":"2024-09-10T20:42:53.378459Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Customer enquired about his Iphone and Apple watch which is not showing his any steps/activity and health activities. Agent is asking to move to DM and look into it.\n","output_type":"stream"}]},{"cell_type":"code","source":"# We do the same for the \"original dialog info\" column in the validation set\nsummary_validation = validation_data[\"original dialog info\"]\nformat_column_summary(summary_validation)\n\n# We print the first row of the validation column as a verification\nprint(summary_validation[0])","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.380433Z","iopub.execute_input":"2024-09-10T20:42:53.381092Z","iopub.status.idle":"2024-09-10T20:42:53.399714Z","shell.execute_reply.started":"2024-09-10T20:42:53.381048Z","shell.execute_reply":"2024-09-10T20:42:53.398848Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Customer is complaining about unable to create similar playlist so that  function does not  work anymore. Agent says could DM the account's email address or username so that they look backstage.\n","output_type":"stream"}]},{"cell_type":"code","source":"# We do the same for the \"original dialog info\" column in the testing set\nsummary_testing = testing_data[\"original dialog info\"]\nformat_column_summary(summary_testing)\n\n# We print the first row of the validation column as a verification\nprint(summary_testing[0])","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.400870Z","iopub.execute_input":"2024-09-10T20:42:53.401228Z","iopub.status.idle":"2024-09-10T20:42:53.422995Z","shell.execute_reply.started":"2024-09-10T20:42:53.401186Z","shell.execute_reply":"2024-09-10T20:42:53.422139Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Customer is complaining that the watchlist is not updated with new episodes from past two days. Agent informed that the team is working hard to investigate to show new episodes on page.\n","output_type":"stream"}]},{"cell_type":"code","source":"#We rename the current columns of the dataset to \"dialog\" and \"summary\" for better understandability\n\ntraining_data.rename(columns={'original dialog info': 'summary', 'log': 'dialog'}, inplace=True)\ntraining_data = training_data[['dialog', 'summary']]\n\nvalidation_data.rename(columns={'original dialog info': 'summary', 'log': 'dialog'}, inplace=True)\nvalidation_data = validation_data[['dialog', 'summary']]\n\ntesting_data.rename(columns={'original dialog info': 'summary', 'log': 'dialog'}, inplace=True)\ntesting_data = testing_data[['dialog', 'summary']]","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.424092Z","iopub.execute_input":"2024-09-10T20:42:53.424458Z","iopub.status.idle":"2024-09-10T20:42:53.435617Z","shell.execute_reply.started":"2024-09-10T20:42:53.424414Z","shell.execute_reply":"2024-09-10T20:42:53.434647Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"**We create Data Dictionary containing all sets to be able and push it to Huggingface Hub to use it for the evaluation part.**","metadata":{}},{"cell_type":"code","source":"# We create Data Dictionary containing all sets to be able to push it to Huggingface Hub and use it for the evaluation part.\n\nfrom datasets import DatasetDict, Dataset\n\ndataset_training = Dataset.from_pandas(training_data)\ndataset_validation = Dataset.from_pandas(validation_data)\ndataset_testing = Dataset.from_pandas(testing_data)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.436864Z","iopub.execute_input":"2024-09-10T20:42:53.437333Z","iopub.status.idle":"2024-09-10T20:42:53.470990Z","shell.execute_reply.started":"2024-09-10T20:42:53.437246Z","shell.execute_reply":"2024-09-10T20:42:53.470238Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# We create a dataset dictionary where we store store the training and validation sets\nfrom datasets import DatasetDict, Dataset\n\nfinal_dataset = DatasetDict({\n    'training': dataset_training,\n    'validation' : dataset_validation,\n    'testing' : dataset_testing\n    })","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.471988Z","iopub.execute_input":"2024-09-10T20:42:53.472280Z","iopub.status.idle":"2024-09-10T20:42:53.476661Z","shell.execute_reply.started":"2024-09-10T20:42:53.472236Z","shell.execute_reply":"2024-09-10T20:42:53.475766Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# We visualise the resulting dataset\nfinal_dataset","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.477806Z","iopub.execute_input":"2024-09-10T20:42:53.478153Z","iopub.status.idle":"2024-09-10T20:42:53.487319Z","shell.execute_reply.started":"2024-09-10T20:42:53.478111Z","shell.execute_reply":"2024-09-10T20:42:53.486456Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    training: Dataset({\n        features: ['dialog', 'summary'],\n        num_rows: 879\n    })\n    validation: Dataset({\n        features: ['dialog', 'summary'],\n        num_rows: 110\n    })\n    testing: Dataset({\n        features: ['dialog', 'summary'],\n        num_rows: 110\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# We store the current dataset to Hugging Face Hub to use it for our the model evaluation\nfinal_dataset.push_to_hub(\"Dialog-Summarization-Dataset\", token=\"...\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:53.488409Z","iopub.execute_input":"2024-09-10T20:42:53.488757Z","iopub.status.idle":"2024-09-10T20:42:54.639324Z","shell.execute_reply.started":"2024-09-10T20:42:53.488714Z","shell.execute_reply":"2024-09-10T20:42:54.638483Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/540 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e3028f5c5cf4f1daccc15716edb0ec7"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datasets/Marouane50/Dialog-Summarization-Dataset/commit/25db6c8fb4473cf1c509f5f62bd5ceadb331a83f', commit_message='Upload dataset', commit_description='', oid='25db6c8fb4473cf1c509f5f62bd5ceadb331a83f', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"**4. CONVERTING THE DATASET INTO THE REQUIRED INSTRUCTION FORMAT**","metadata":{}},{"cell_type":"markdown","source":"**To be able to fine-tune the Llama2-7b-chat model, we need a to convert the dataset into the required instruction format for the model. Each row in the instruction dataset should be in the format:**\n\n[INST] <<SYS>> {{system_prompt}} <</SYS>> {{input}} [/INST] {{summary}} \n\n**Where: {{ system_prompt }} represents the default prompt used in the dataset, {{ input }} represents the dialog to be summarised, and summary represents the corresponding summary of the dialog.**\n    \n**So we need to reformat the current dataset to match this specific format.**","metadata":{}},{"cell_type":"code","source":"# We create a default_prompt that will be used as a system prompt in the instruction dataset\ndefault_prompt = \"The following text is a conversation between a user and an AI agent. Write a summary of the conversation.\"","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:54.640363Z","iopub.execute_input":"2024-09-10T20:42:54.640627Z","iopub.status.idle":"2024-09-10T20:42:54.645061Z","shell.execute_reply.started":"2024-09-10T20:42:54.640598Z","shell.execute_reply":"2024-09-10T20:42:54.644110Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# We convert the training set into the instruction format for the Llama2 chat model\nimport pandas as pd\n\ndf_training = pd.DataFrame(dataset_training)\n\ndf_training['text'] = df_training.apply(\n    lambda row: f\"\"\"<s> [INST] <<SYS>> {default_prompt} <</SYS>> {row['dialog']} [/INST] {row['summary']} </s>\"\"\",axis=1\n)\n\ndataset_training = df_training[['text']]","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:54.646072Z","iopub.execute_input":"2024-09-10T20:42:54.646402Z","iopub.status.idle":"2024-09-10T20:42:54.706428Z","shell.execute_reply.started":"2024-09-10T20:42:54.646370Z","shell.execute_reply":"2024-09-10T20:42:54.705575Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# We convert the training set into the instruction format for the Llama2 chat model\ndf_validation = pd.DataFrame(dataset_validation)\n\ndf_validation['text'] = df_validation.apply(\n    lambda row: f\"\"\"<s> [ INST] <<SYS>> {default_prompt} <</SYS>> {row['dialog']} [/INST] {row['summary']} </s>\"\"\",axis=1\n)\n\ndataset_validation = df_validation[['text']]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:54.707445Z","iopub.execute_input":"2024-09-10T20:42:54.707719Z","iopub.status.idle":"2024-09-10T20:42:54.720367Z","shell.execute_reply.started":"2024-09-10T20:42:54.707687Z","shell.execute_reply":"2024-09-10T20:42:54.719456Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# We convert the datasets from pandas into the format required to store it  used in Hugging Face Hub, the testing set will not be used during the training\ndataset_training_formatted = Dataset.from_pandas(dataset_training)\ndataset_validation_formatted = Dataset.from_pandas(dataset_validation)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:54.721719Z","iopub.execute_input":"2024-09-10T20:42:54.722126Z","iopub.status.idle":"2024-09-10T20:42:54.743327Z","shell.execute_reply.started":"2024-09-10T20:42:54.722071Z","shell.execute_reply":"2024-09-10T20:42:54.742475Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# We create a dataset dictionary where we store store the training and validation sets\nfrom datasets import DatasetDict, Dataset\n\nfinal_dataset_formatted = DatasetDict({\n    'training': dataset_training_formatted,\n    'validation' : dataset_validation_formatted\n    })\n","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:54.744246Z","iopub.execute_input":"2024-09-10T20:42:54.744547Z","iopub.status.idle":"2024-09-10T20:42:54.749588Z","shell.execute_reply.started":"2024-09-10T20:42:54.744500Z","shell.execute_reply":"2024-09-10T20:42:54.748618Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# We visualise content of the dataset dictionary \nfinal_dataset_formatted","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:54.750762Z","iopub.execute_input":"2024-09-10T20:42:54.751144Z","iopub.status.idle":"2024-09-10T20:42:54.759764Z","shell.execute_reply.started":"2024-09-10T20:42:54.751075Z","shell.execute_reply":"2024-09-10T20:42:54.758793Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    training: Dataset({\n        features: ['text'],\n        num_rows: 879\n    })\n    validation: Dataset({\n        features: ['text'],\n        num_rows: 110\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"**Our final dataset is now ready, we can now push it to Hugging Face Hub**","metadata":{}},{"cell_type":"code","source":"# We store the final formatted dataset in Hugging Face Hub to use it for finetuning.\nfinal_dataset_formatted.push_to_hub(\"Dialog-Summarization-Dataset-Formatted\", token=\"...\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T20:42:54.760757Z","iopub.execute_input":"2024-09-10T20:42:54.761127Z","iopub.status.idle":"2024-09-10T20:42:55.745449Z","shell.execute_reply.started":"2024-09-10T20:42:54.761094Z","shell.execute_reply":"2024-09-10T20:42:55.744555Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/396 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6be9d75409ce464894567524dd9a593d"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datasets/Marouane50/Dialog-Summarization-Dataset-Formatted/commit/24e6007483f48ae8253a4f8d2e69001d65ec1919', commit_message='Upload dataset', commit_description='', oid='24e6007483f48ae8253a4f8d2e69001d65ec1919', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"Reference: TweetSum Dataset https://huggingface.co/datasets/Salesforce/dialogstudio/tree/main/dialogue_summarization/TweetSumm","metadata":{}}]}