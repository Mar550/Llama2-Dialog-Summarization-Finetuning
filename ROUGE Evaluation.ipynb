{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h2> Evaluation of Dialog Summarization </h2>","metadata":{}},{"cell_type":"markdown","source":"**LOADING DATASET**","metadata":{}},{"cell_type":"markdown","source":"**1. We install the necessary packages and libraries we will need for ou evaluation**","metadata":{}},{"cell_type":"code","source":"!pip install evaluate\n!pip install datasets\n!pip install rouge_score\n!pip install --user -U nltk\n!pip install transformers\n!pip install -U bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-08-16T21:17:42.765937Z","iopub.execute_input":"2024-08-16T21:17:42.766227Z","iopub.status.idle":"2024-08-16T21:19:06.597284Z","shell.execute_reply.started":"2024-08-16T21:17:42.766200Z","shell.execute_reply":"2024-08-16T21:19:06.596248Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.20.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.5.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.2\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=48065f226d1428a24eb1f692219f8f4d81acdde778c33a6317130d0b2cd50e1a\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nCollecting nltk\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.4)\nDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nltk\n\u001b[33m  WARNING: The script nltk is installed in '/root/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nltk-3.8.1\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**2. We load the dataset we will use for the evaluation**","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"Marouane50/Dialog-Summarization-Dataset\", split=\"testing\")\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-16T21:19:06.599264Z","iopub.execute_input":"2024-08-16T21:19:06.599613Z","iopub.status.idle":"2024-08-16T21:19:12.094914Z","shell.execute_reply.started":"2024-08-16T21:19:06.599582Z","shell.execute_reply":"2024-08-16T21:19:12.093958Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/540 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0e1c3fabe2f409cb4d81b020e88a0ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/627k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbc8b7acf699497aae758531f2632966"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/82.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5aa631121ae4a8ea242ecba6fd624ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/89.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7179a83fd4404830aa36fca1944d6997"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating training split:   0%|          | 0/879 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b9aca9968354220853def6a7fe035ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9267bfb4fd6f4b2d8ab42fa68ad483f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating testing split:   0%|          | 0/110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"150eb4f70a204acd93208b08c80bb14e"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['dialog', 'summary'],\n    num_rows: 110\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset[\"summary\"][1]","metadata":{"execution":{"iopub.status.busy":"2024-08-16T22:34:35.257737Z","iopub.execute_input":"2024-08-16T22:34:35.258026Z","iopub.status.idle":"2024-08-16T22:34:35.273000Z","shell.execute_reply.started":"2024-08-16T22:34:35.258001Z","shell.execute_reply":"2024-08-16T22:34:35.272057Z"},"trusted":true},"execution_count":101,"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"'Customer is asking about the ACC to link to the current  number. Agent says that they have updated their case manager.'"},"metadata":{}}]},{"cell_type":"markdown","source":"**3. From the testing set of the dataset, we select a 10 random samples of dialogs and summaries pairs that we will use as reference values for the evaluation.**","metadata":{}},{"cell_type":"code","source":"import random\nreference_summaries=[]\nreference_dialogs = []\n\ndef get_random_summaries(dataset):\n    for i in range(0,10):\n        index = random.randint(0,109)\n        dataset[\"summary\"][index]\n        reference_summaries.append(dataset[\"summary\"][index])  # Append the summary to the reference summaries list\n        reference_dialogs.append(dataset[\"dialog\"][index])  # Append the dialog to the reference dialogs list\n\nget_random_summaries(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T21:19:12.109998Z","iopub.execute_input":"2024-08-16T21:19:12.110316Z","iopub.status.idle":"2024-08-16T21:19:12.127037Z","shell.execute_reply.started":"2024-08-16T21:19:12.110285Z","shell.execute_reply":"2024-08-16T21:19:12.126054Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**LOADING MODELS**","metadata":{}},{"cell_type":"markdown","source":"1. We load the base model and the fine-tuned model from Hugging Face Hub","metadata":{}},{"cell_type":"code","source":"base_model_name = \"NousResearch/Llama-2-7b-chat-hf\"\ntrained_model_name = \"Marouane50/Llama2-Dialog-Summarization\"","metadata":{"execution":{"iopub.status.busy":"2024-08-16T21:19:12.128155Z","iopub.execute_input":"2024-08-16T21:19:12.128460Z","iopub.status.idle":"2024-08-16T21:19:12.137213Z","shell.execute_reply.started":"2024-08-16T21:19:12.128436Z","shell.execute_reply":"2024-08-16T21:19:12.136393Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**2. We set up a QLoRA configuration and use it to load the models using quantization (same code as in finetuning file)**","metadata":{}},{"cell_type":"code","source":"import torch\nimport os\nfrom transformers import BitsAndBytesConfig\n\ncompute_dtype = getattr(torch, \"float16\")\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype= compute_dtype,\n    bnb_4bit_use_double_quant=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T21:19:12.139490Z","iopub.execute_input":"2024-08-16T21:19:12.140033Z","iopub.status.idle":"2024-08-16T21:19:16.115125Z","shell.execute_reply.started":"2024-08-16T21:19:12.140001Z","shell.execute_reply":"2024-08-16T21:19:16.114298Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**3. We load the base model Llama2 7B chat and use it to run a text generation pipeline**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model_name,\n    quantization_config = bnb_config,\n    device_map = {\"\": 0},\n)\n\n# Llama Tokenizer configuration\ntokenizer = AutoTokenizer.from_pretrained(base_model_name, add_eos_token=True, use_fast=True)\ntokenizer.pad_token_id = 18610\ntokenizer.padding_side = \"right\"\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T21:19:16.116440Z","iopub.execute_input":"2024-08-16T21:19:16.117045Z","iopub.status.idle":"2024-08-16T21:20:28.106934Z","shell.execute_reply.started":"2024-08-16T21:19:16.117011Z","shell.execute_reply":"2024-08-16T21:20:28.105910Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4e77c9992f74450b367dda142d63552"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4831325af36842d5a4964875ccfd30b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9156ee4fb764538833af6bb48ab740d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a28841dd5d34314b1597ea0449c4998"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d25cbe7a50b140ce9daa1d550a9017c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd86e95da82349558add1faa61323e12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8de7ae279df04e7880bc875a801d1db5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4af5b394daee4130a5d8d36168c7d7f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da3965b59df34d90b85d8c1e0d481ee9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d59e582769e487a8cd63dc63105c899"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6299a13f62a74dedb982d8d8439b02f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f04b73e86ac4240b166ada07665cd79"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\n\n# In this case, we need to specify in the prompt that the summary should be 180 characters maximum, to match the length of the summaries in our dataset.\nsystem_prompt = \"The following text is a conversation between a human and an AI agent. Write a 150 characters maximum summary of the conversation.\"\n\npipe = pipeline(\n    task=\"text-generation\",\n    model=model, \n    tokenizer=tokenizer, \n    max_length=1000 \n)\n\n# We use the first dialog from the testing set as an input, to be able to compare the output with the testing set summary\nbase_model_summaries = []\nfor i in range(0, 10):\n    result = pipe(f\"<s>[INST] <<SYS>> {system_prompt} <</SYS>> {reference_dialogs[i]} [/INST]\")\n    base_model_summaries.append(result[0]['generated_text'])\n    \nprint(base_model_summaries[1])","metadata":{"execution":{"iopub.status.busy":"2024-08-16T22:39:18.571682Z","iopub.execute_input":"2024-08-16T22:39:18.572509Z","iopub.status.idle":"2024-08-16T22:40:43.215066Z","shell.execute_reply.started":"2024-08-16T22:39:18.572472Z","shell.execute_reply":"2024-08-16T22:40:43.214082Z"},"trusted":true},"execution_count":119,"outputs":[{"name":"stdout","text":"<s>[INST] <<SYS>> The following text is a conversation between a human and an AI agent. Write a 150 characters maximum summary of the conversation. <</SYS>> user: the new update ios11 sucks. I can’t even use some apps on my phone.\nagent: We want your iPhone to work properly, and we are here for you. Which apps are giving you trouble, and which iPhone?\nuser: 6s. Words with friends  Words pro\nagent: Do you see app updates in App Store &gt; Updates? Also, are you using iOS 11.0.3?\nuser: I am using 11.0.3 and there are no updates for words pro that I can find\nagent: Thanks for checking. Next, what happens in that app that makes it unusable?\nuser: It’s says it’s not compatible.\nagent: Thanks for confirming this. Send us a DM and we'll work from there: \n [/INST]  Sure! Here is a 150 character summary of the conversation:\n\nUser: New iOS 11 update is terrible, can't use some apps on my iPhone 6s. Specifically, Words with Friends and Words Pro. Agent: Checked for updates in App Store, user is using iOS 11.0.3. User: App says it's not compatible. Agent: Send a DM for further assistance.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**3. Then we load the fine-tuned model and use it to run another text generation pipeline**","metadata":{}},{"cell_type":"code","source":"# Trained Model configuration\nfinetuned_model = AutoModelForCausalLM.from_pretrained(\n    trained_model_name,\n    quantization_config = bnb_config,\n    device_map = {\"\": 0},\n)\n\n# Llama Tokenizer configuration\ntokenizer = AutoTokenizer.from_pretrained(trained_model_name, add_eos_token=True, use_fast=True)\ntokenizer.pad_token_id = 18610\ntokenizer.padding_side = \"right\"\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T21:22:25.556230Z","iopub.execute_input":"2024-08-16T21:22:25.556867Z","iopub.status.idle":"2024-08-16T21:23:49.582802Z","shell.execute_reply.started":"2024-08-16T21:22:25.556838Z","shell.execute_reply":"2024-08-16T21:23:49.582013Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fe74c899eb444f38dd3cf0dd5d27cc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7668901d15104b7084e8a36999b5b00f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a0dac2c64e0499b88bb90aae50d4bfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a701174e15bc4020bb9b754b6bb966b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fe0700cf2cd4888bfda3ff88dc28aa1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc8fa0fc14634fd6949a03293c2c03ff"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cac5dc0abee94616a80900227361a7d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/695 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67855c3943224375a00cdc587469c9a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cec262790f8642b7a10e22f263d780cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"559d6e7580834805a20240f9e17e3ec4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c9feaca5ea24715bcb2f33616edd39e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89ada86973974ef7b39d7bc476fc1698"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\n\nsystem_prompt = \"The following text is a conversation between a human and an AI agent. Write a summary of the conversation.\"\n\npipe = pipeline(\n    task=\"text-generation\",\n    model=finetuned_model, \n    tokenizer=tokenizer, \n    max_length=1000 \n)\n\n# We use the first dialog from the testing set as an input, to be able to compare the output with the testing set summary\ntrained_model_summaries = []\nfor i in range(0, 10):\n    result = pipe(f\"<s>[INST] <<SYS>> {system_prompt} <</SYS>> {reference_dialogs[i]} [/INST]\")\n    trained_model_summaries.append(result[0]['generated_text'])\n    \ntrained_model_summaries[1]\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T22:32:44.789250Z","iopub.execute_input":"2024-08-16T22:32:44.790178Z","iopub.status.idle":"2024-08-16T22:33:05.957973Z","shell.execute_reply.started":"2024-08-16T22:32:44.790144Z","shell.execute_reply":"2024-08-16T22:33:05.957007Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"\"<s>[INST] <<SYS>> The following text is a conversation between a human and an AI agent. Write a summary of the conversation. <</SYS>> user: the new update ios11 sucks. I can’t even use some apps on my phone.\\nagent: We want your iPhone to work properly, and we are here for you. Which apps are giving you trouble, and which iPhone?\\nuser: 6s. Words with friends  Words pro\\nagent: Do you see app updates in App Store &gt; Updates? Also, are you using iOS 11.0.3?\\nuser: I am using 11.0.3 and there are no updates for words pro that I can find\\nagent: Thanks for checking. Next, what happens in that app that makes it unusable?\\nuser: It’s says it’s not compatible.\\nagent: Thanks for confirming this. Send us a DM and we'll work from there: \\n [/INST]\\n    The customer is complaining about the new update ios11 sucks. The agent asked to DM and they will work from there. The customer is using 11.0.3 and there are no updates for words pro that he can find.</s>\""},"metadata":{}}]},{"cell_type":"markdown","source":"The output generated by both models are not enough to evaluate. It happens that sometimes we get irregular patterns inside of the text. So we won't be able to use automated testing. \nThe alternative we chose is to use manual testing where we manually copy the summary from the output and use it to compute the ROUGE score, considering we're only testing 10 summaries, it shouldn't be very complicated.","metadata":{}},{"cell_type":"markdown","source":"<h1> Evaluating the Models </h1>","metadata":{}},{"cell_type":"markdown","source":"**We use the rouge metric from the evaluate library to evaluate the summaries**","metadata":{}},{"cell_type":"code","source":"import evaluate\n\nrouge_score = evaluate.load(\"rouge\") # We load the ROUGE metric from the evaluate libray, used to evaluate performance of NLP models","metadata":{"execution":{"iopub.status.busy":"2024-08-16T22:37:33.865021Z","iopub.execute_input":"2024-08-16T22:37:33.865757Z","iopub.status.idle":"2024-08-16T22:37:34.332814Z","shell.execute_reply.started":"2024-08-16T22:37:33.865722Z","shell.execute_reply":"2024-08-16T22:37:34.331872Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"markdown","source":"**We create a function to preprocess the summaries text into the right format for ROUGE evaluation**","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import sent_tokenize\n\ndef compute_rouge_score(generated, reference):\n    #We need to add '\\n' to each line before send it to ROUGE\n    generated_with_newlines = [\"\\n\".join(sent_tokenize(s.strip())) for s in generated]\n    reference_with_newlines = [\"\\n\".join(sent_tokenize(s.strip())) for s in reference]\n    \n    return rouge_score.compute(\n        predictions=generated_with_newlines,\n        references=reference_with_newlines,\n        use_stemmer=True,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-08-16T22:37:41.865396Z","iopub.execute_input":"2024-08-16T22:37:41.866306Z","iopub.status.idle":"2024-08-16T22:37:41.871872Z","shell.execute_reply.started":"2024-08-16T22:37:41.866271Z","shell.execute_reply":"2024-08-16T22:37:41.870943Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"markdown","source":"**We set the variables containing the summaries data**","metadata":{}},{"cell_type":"code","source":"reference_summary = [\"Customer is asking about the ACC to link to the current  number. Agent says that they have updated their case manager.\"]\nbase_model_summary  = [\"User: New iOS 11 update is terrible, can't use some apps on my iPhone 6s. Specifically, Words with Friends and Words Pro. Agent: Checked for updates in App Store, user is using iOS 11.0.3. User: App says it's not compatible. Agent: Send a DM for further assistance.\"]\ntrained_model_summary = [\"The customer is complaining about the new update ios11 sucks. The agent asked to DM and they will work from there. The customer is using 11.0.3 and there are no updates for words pro that he can find.\"]\n","metadata":{"execution":{"iopub.status.busy":"2024-08-16T22:41:10.528047Z","iopub.execute_input":"2024-08-16T22:41:10.529147Z","iopub.status.idle":"2024-08-16T22:41:10.535151Z","shell.execute_reply.started":"2024-08-16T22:41:10.529101Z","shell.execute_reply":"2024-08-16T22:41:10.534104Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"reference_summary","metadata":{"execution":{"iopub.status.busy":"2024-08-16T22:41:12.309209Z","iopub.execute_input":"2024-08-16T22:41:12.310090Z","iopub.status.idle":"2024-08-16T22:41:12.315959Z","shell.execute_reply.started":"2024-08-16T22:41:12.310056Z","shell.execute_reply":"2024-08-16T22:41:12.315094Z"},"trusted":true},"execution_count":121,"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"['Customer is asking about the ACC to link to the current  number. Agent says that they have updated their case manager.']"},"metadata":{}}]},{"cell_type":"markdown","source":"**We calculate the ROUGE score for the base model**","metadata":{}},{"cell_type":"code","source":"compute_rouge_score(trained_model_summary, reference_summary)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T22:38:14.056816Z","iopub.execute_input":"2024-08-16T22:38:14.057617Z","iopub.status.idle":"2024-08-16T22:38:14.276545Z","shell.execute_reply.started":"2024-08-16T22:38:14.057583Z","shell.execute_reply":"2024-08-16T22:38:14.275591Z"},"trusted":true},"execution_count":117,"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"{'rouge1': 0.36065573770491804,\n 'rouge2': 0.06779661016949151,\n 'rougeL': 0.2622950819672132,\n 'rougeLsum': 0.32786885245901637}"},"metadata":{}}]},{"cell_type":"markdown","source":"**We calculate the ROUGE score for the fine-tuned model**","metadata":{}},{"cell_type":"code","source":"compute_rouge_score(base_model_summary, reference_summary)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T22:41:17.589808Z","iopub.execute_input":"2024-08-16T22:41:17.590462Z","iopub.status.idle":"2024-08-16T22:41:17.806648Z","shell.execute_reply.started":"2024-08-16T22:41:17.590431Z","shell.execute_reply":"2024-08-16T22:41:17.805687Z"},"trusted":true},"execution_count":122,"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"{'rouge1': 0.1111111111111111,\n 'rouge2': 0.0,\n 'rougeL': 0.08333333333333333,\n 'rougeLsum': 0.1111111111111111}"},"metadata":{}}]},{"cell_type":"markdown","source":"The higher the ROUGE score for all metrics (Rouge1, Rouge2, RougeL, RougeLsum) the better the performance of the model in dialog summarization compared to the reference summaries in the dataset. The evaluation of the fine-tuned model should show higher ROUGE score than the base model when compared to the testing set summaries to prove that the training had an effect.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}