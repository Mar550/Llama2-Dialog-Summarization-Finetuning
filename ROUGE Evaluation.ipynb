{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h2> Evaluation of Dialog Summarization </h2>","metadata":{}},{"cell_type":"markdown","source":"**LOADING DATASET**","metadata":{}},{"cell_type":"markdown","source":"**1. We install the necessary packages and libraries we will need for ou evaluation**","metadata":{}},{"cell_type":"code","source":"!pip install evaluate\n!pip install datasets\n!pip install rouge_score\n!pip install --user -U nltk\n!pip install transformers\n!pip install -U bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:12:58.841214Z","iopub.execute_input":"2024-08-19T22:12:58.842016Z","iopub.status.idle":"2024-08-19T22:14:26.934575Z","shell.execute_reply.started":"2024-08-19T22:12:58.841986Z","shell.execute_reply":"2024-08-19T22:14:26.932913Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.20.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.5.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.2\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=f7550156e8e2e3b248c0e2cf14d012015e5935806f0cdeb33218bc2089c5a24b\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nCollecting nltk\n  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.4)\nDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nltk\n\u001b[33m  WARNING: The script nltk is installed in '/root/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nltk-3.9.1\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\nRequirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.5.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**2. We load the dataset we will use for the evaluation**","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"Marouane50/Dialog-Summarization-Dataset\", split=\"testing\")\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:14:26.936987Z","iopub.execute_input":"2024-08-19T22:14:26.937329Z","iopub.status.idle":"2024-08-19T22:14:32.551994Z","shell.execute_reply.started":"2024-08-19T22:14:26.937297Z","shell.execute_reply":"2024-08-19T22:14:32.551096Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/540 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b838a04a722a42f9aebc95193ff7829e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/627k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"257c8dccf45346bb94dcb1ef0f34a0ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/82.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d33769b3789479eabcddfe2968bedf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/89.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23ede8e1ab8e4ceea78f99ba7bdccce7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating training split:   0%|          | 0/879 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e26e888cd7e740e0b0f8101684231124"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f961f8779ff4c2992cf513dc38c2480"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating testing split:   0%|          | 0/110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ae1045bd0ae4a44913e5f1a85f1f4bf"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['dialog', 'summary'],\n    num_rows: 110\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"**3. From the testing set of the dataset, we select a 10 random samples of dialogs and summaries pairs that we will use as reference values for the evaluation.**","metadata":{}},{"cell_type":"code","source":"import random\nreference_summaries=[]\nreference_dialogs = []\n\ndef get_random_summaries(dataset):\n    for i in range(0,10):\n        index = random.randint(0,109)\n        dataset[\"summary\"][index]\n        reference_summaries.append(dataset[\"summary\"][index])  # Append the summary to the reference summaries list\n        reference_dialogs.append(dataset[\"dialog\"][index])  # Append the dialog to the reference dialogs list\n\nget_random_summaries(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:14:32.557325Z","iopub.execute_input":"2024-08-19T22:14:32.557625Z","iopub.status.idle":"2024-08-19T22:14:32.575228Z","shell.execute_reply.started":"2024-08-19T22:14:32.557599Z","shell.execute_reply":"2024-08-19T22:14:32.574215Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(reference_summaries[1])","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:14:32.576237Z","iopub.execute_input":"2024-08-19T22:14:32.576514Z","iopub.status.idle":"2024-08-19T22:14:32.587142Z","shell.execute_reply.started":"2024-08-19T22:14:32.576490Z","shell.execute_reply":"2024-08-19T22:14:32.585923Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Customer is complaining about the new updates IOS11 and can't even use some apps on phone. Agent asks to send a DM and work from there URL.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**LOADING MODELS**","metadata":{}},{"cell_type":"markdown","source":"1. We load the base model and the fine-tuned model from Hugging Face Hub","metadata":{}},{"cell_type":"code","source":"base_model_name = \"NousResearch/Llama-2-7b-chat-hf\"\ntrained_model_name = \"Marouane50/Dialog-Summarization-Finetuning\"","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:14:32.588602Z","iopub.execute_input":"2024-08-19T22:14:32.589077Z","iopub.status.idle":"2024-08-19T22:14:32.597864Z","shell.execute_reply.started":"2024-08-19T22:14:32.589043Z","shell.execute_reply":"2024-08-19T22:14:32.596742Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"**2. We set up a QLoRA configuration and use it to load the models using quantization (same code as in finetuning file)**","metadata":{}},{"cell_type":"code","source":"import torch\nimport os\nfrom transformers import BitsAndBytesConfig\n\ncompute_dtype = getattr(torch, \"float16\")\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype= compute_dtype,\n    bnb_4bit_use_double_quant=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:14:32.599271Z","iopub.execute_input":"2024-08-19T22:14:32.599685Z","iopub.status.idle":"2024-08-19T22:14:34.580716Z","shell.execute_reply.started":"2024-08-19T22:14:32.599648Z","shell.execute_reply":"2024-08-19T22:14:34.579674Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**3. We load the base model Llama2 7B chat and use it to run a text generation pipeline**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model_name,\n    quantization_config = bnb_config,\n    device_map = {\"\": 0},\n)\n\n# Llama Tokenizer configuration\ntokenizer = AutoTokenizer.from_pretrained(base_model_name, add_eos_token=True, use_fast=True)\ntokenizer.pad_token_id = 18610\ntokenizer.padding_side = \"right\"\n","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:14:34.582311Z","iopub.execute_input":"2024-08-19T22:14:34.583529Z","iopub.status.idle":"2024-08-19T22:16:00.177639Z","shell.execute_reply.started":"2024-08-19T22:14:34.583490Z","shell.execute_reply":"2024-08-19T22:16:00.176601Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3db471bdf3a4695b5e4d67556d34900"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1a84b2d3e9f46f592daee266afab504"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a23c1c54b9b04feb9eace5cf3f26105c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddd9b1cf4c7443d8846232d45187f2c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2409979d527489ea395467c8c737eca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbeac519214941ef8acb3fbf4a8c6099"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92765e00711c4a9e8e3c5088ea9a47dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ccca503f6b7416db7419728968be756"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e48a98b4faf54ae0805fe580f728af83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6d3d106f75e4184bd26b50254a0ccf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db34c75089cd489f812e82949dfdfd4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdf1fb77434f4986b3a35537ceb574b4"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\n\n# In this case, we need to specify in the prompt that the summary should only contain two sentences, to match the length of the summaries in our dataset.\nsystem_prompt = \"The following text is a conversation between a human and an AI agent. Write a summary of the conversation in two sentence.\"\n\npipe = pipeline(\n    task=\"text-generation\",\n    model=model, \n    tokenizer=tokenizer, \n    max_length=1000 \n)\n\n# We use the first dialog from the testing set as an input, to be able to compare the output with the testing set summary\nbase_model_summaries = []\nfor i in range(0, 10):\n    result = pipe(f\"<s>[INST] <<SYS>> {system_prompt} <</SYS>> {reference_dialogs[i]} [/INST]\")\n    base_model_summaries.append(result[0]['generated_text'])\n    \nprint(base_model_summaries[2])","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:35:33.771437Z","iopub.execute_input":"2024-08-19T22:35:33.771799Z","iopub.status.idle":"2024-08-19T22:37:16.699360Z","shell.execute_reply.started":"2024-08-19T22:35:33.771773Z","shell.execute_reply":"2024-08-19T22:37:16.698330Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"<s>[INST] <<SYS>> The following text is a conversation between a human and an AI agent. Write a summary of the conversation in two sentence. <</SYS>> user: signed up for $75 package June of '17. We've been charged $200+ /month since then. Now received cancellation letter..??!!!? ?\nagent: Hi, I would love to help. Please DM me the phone # associated with the account &amp; the service address. -Jules\nuser: 6157177213\n1833 Winding Way Dr. White House, TN 37188\nagent: Thanks, do you have the account # on hand as well? -Jules\nuser:   credit card  \nagent: Thanks, I am seeing that this account was disconnected on 09/29/17. Did you just receive a letter now? -Jules\nuser: Yes. Are you able to review the billing charges?\nagent: What is your full name? -MV\n [/INST]  Sure! Here is a summary of the conversation between the human and the AI agent:\n\nThe human has been charged $200+ per month since June 2017 after signing up for a $75 package. They have now received a cancellation letter, despite the account being disconnected on September 29, 2017. The AI agent is asking for the human's full name and account information in order to review the billing charges.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(base_model_summaries[])","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:39:05.012339Z","iopub.execute_input":"2024-08-19T22:39:05.013224Z","iopub.status.idle":"2024-08-19T22:39:05.018026Z","shell.execute_reply.started":"2024-08-19T22:39:05.013190Z","shell.execute_reply":"2024-08-19T22:39:05.016965Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"<s>[INST] <<SYS>> The following text is a conversation between a human and an AI agent. Write a summary of the conversation in two sentence. <</SYS>> user:Even when someone tries their hardest to rectify the situation and you still don't have compassion? #notmybank \nagent: Hi, Giselle. I'd like to see how we can help with your fees.   Pls click below send your name/ZIP/phone #/acct type so our Social Care Team can follow up with you.  \nuser: I spoke to a manager in the customer service department this morning who told me you all could not help me with my overdraft fees  even after all the circumstances and me rarely over drafting and paying back the funds ASAP after I saw the overdraft.  I just feel like there was a total lack of compassion and when someone asks you why your account was so low, it's insulting.\nagent: Please let us know if you change your mind and would like us to review your account with you. We are here to help. \nuser: I tried clicking the link you sent to send my info and it didn't work.\nagent: Here is the link again.  \n [/INST]  Sure! Here is a summary of the conversation in two sentences:\n\nThe human, Giselle, is frustrated with her bank's lack of compassion after speaking with a manager in the customer service department who refused to help her with her overdraft fees, despite her history of paying back the funds quickly. The AI agent responds by offering to review Giselle's account with her and provides a link for her to send her information.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**3. Then we load the fine-tuned model and use it to run another text generation pipeline**","metadata":{}},{"cell_type":"code","source":"# Trained Model configuration\nfinetuned_model = AutoModelForCausalLM.from_pretrained(\n    trained_model_name,\n    quantization_config = bnb_config,\n    device_map = {\"\": 0},\n)\n\n# Llama Tokenizer configuration\ntokenizer = AutoTokenizer.from_pretrained(trained_model_name, add_eos_token=True, use_fast=True)\ntokenizer.pad_token_id = 18610\ntokenizer.padding_side = \"right\"\n","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:17:26.085286Z","iopub.execute_input":"2024-08-19T22:17:26.085882Z","iopub.status.idle":"2024-08-19T22:20:52.529748Z","shell.execute_reply.started":"2024-08-19T22:17:26.085855Z","shell.execute_reply":"2024-08-19T22:20:52.528629Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/632 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8a6f4d52f444a01b3b081c70afed48b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"defc6df2cd9845c79d789d0d0a4ca8a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d18a4791c84546b8abdc10a4108d9652"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8236eb4ada5141399859199b7f9ede72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0013ce406dfe47e0b3e70986ac16071f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b1135eef6f0441385067587e6b658d8"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1318f2ee79b04a9cad46eba934ce225a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/695 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"388795fd52534318930bceccd2721b66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"315da0d89eb645d288a5bd9f295a187d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41f89838c90a485bbfab361801e7b18d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec4a13cf73c2456b9c04f37700718b4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"691de94053054b3d88a6f74b9a98d387"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\n\nsystem_prompt = \"The following text is a conversation between a human and an AI agent. Write a summary of the conversation.\"\n\npipe = pipeline(\n    task=\"text-generation\",\n    model=finetuned_model, \n    tokenizer=tokenizer, \n    max_length=1000 \n)\n\n# We use the first dialog from the testing set as an input, to be able to compare the output with the testing set summary\ntrained_model_summaries = []\nfor i in range(0, 10):\n    result = pipe(f\"<s>[INST] <<SYS>> {system_prompt} <</SYS>> {reference_dialogs[i]} [/INST]\")\n    trained_model_summaries.append(result[0]['generated_text'])\n    \ntrained_model_summaries[1]","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:20:52.531154Z","iopub.execute_input":"2024-08-19T22:20:52.531833Z","iopub.status.idle":"2024-08-19T22:21:26.054240Z","shell.execute_reply.started":"2024-08-19T22:20:52.531790Z","shell.execute_reply":"2024-08-19T22:21:26.053277Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"\"<s>[INST] <<SYS>> The following text is a conversation between a human and an AI agent. Write a summary of the conversation. <</SYS>> user: the new update ios11 sucks. I can’t even use some apps on my phone.\\nagent: We want your iPhone to work properly, and we are here for you. Which apps are giving you trouble, and which iPhone?\\nuser: 6s. Words with friends  Words pro\\nagent: Do you see app updates in App Store &gt; Updates? Also, are you using iOS 11.0.3?\\nuser: I am using 11.0.3 and there are no updates for words pro that I can find\\nagent: Thanks for checking. Next, what happens in that app that makes it unusable?\\nuser: It’s says it’s not compatible.\\nagent: Thanks for confirming this. Send us a DM and we'll work from there: \\n [/INST] Customer is complaining about the new update iOS 11. Agent asks to send DM and they will work from there.\""},"metadata":{}}]},{"cell_type":"code","source":"def clean_base_summaries(generated_summaries):\n    for i in range(0,len(generated_summaries)):\n        text = generated_summaries[i]\n        index = text.find(\"\\n\\n\")\n        summary = text[index:]\n        summary = summary.strip()\n        generated_summaries[i] = summary\n        i += 1\n        \ndef clean_trained_summaries(generated_summaries):\n    for i in range(0,len(generated_summaries)):\n        text = generated_summaries[i]\n        index = text.find(\"[/INST]\")\n        summary = text[index+8:]\n        summary = summary.strip()\n        generated_summaries[i] = summary\n        i += 1","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:40:43.217738Z","iopub.execute_input":"2024-08-19T22:40:43.218608Z","iopub.status.idle":"2024-08-19T22:40:43.230361Z","shell.execute_reply.started":"2024-08-19T22:40:43.218566Z","shell.execute_reply":"2024-08-19T22:40:43.229323Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"clean_base_summaries(base_model_summaries) \nbase_model_summaries","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:40:44.117928Z","iopub.execute_input":"2024-08-19T22:40:44.118310Z","iopub.status.idle":"2024-08-19T22:40:44.124760Z","shell.execute_reply.started":"2024-08-19T22:40:44.118280Z","shell.execute_reply":"2024-08-19T22:40:44.123720Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"['The human subscribed to a music streaming service but is unable to play songs as it keeps telling them to subscribe. The AI agent tries to help by asking the human to confirm their account and providing a link to connect with a specialist to sort out the issue.\\n\\nThe human provides screenshots and details of the problem, and the AI agent thanks them for the information. The AI agent then offers to connect the human with a Play Music specialist to help resolve the issue.',\n 'The user is experiencing issues with the new iOS 11 update on their iPhone 6s, specifically with the Words With Friends and Words Pro apps. The AI agent is helping the user troubleshoot the issue by asking questions and offering support.',\n \"The human has been charged $200+ per month since June 2017 after signing up for a $75 package. They have now received a cancellation letter, despite the account being disconnected on September 29, 2017. The AI agent is asking for the human's full name and account information in order to review the billing charges.\",\n '.',\n \"The human, Jenn, had a poor dining experience with a food delivery service where the food was cold and soggy, and they were only refunded the cost of a drink despite having to throw away an entire meal. Jenn contacted the company's customer service and was initially sent an email response, but they did not receive a follow-up call or email as promised. Jenn expressed frustration with the poor service and the fact that they were still charged for a meal they could not eat. The AI agent apologized for the inconvenience and promised to escalate the issue to a specialist, but Jenn expressed skepticism about the effectiveness of this approach.\\n\\nThe AI agent replied by suggesting that Jenn follow up via the app to streamline all communication in one support thread. The agent also acknowledged the mistakes and poor service and apologized again for any inconvenience caused.\",\n \"The human, David, is trying to get home with his disabled wife after realizing they need to change trains during their journey from London Euston to Liverpool. The AI agent suggests booking assistance with Journey Care, which can help with the change of trains, but David explains that they already have assistance and the issue is that they don't want to change trains. The agent apologizes and explains that the only way to change the journey would be to pay for a change of journey.\",\n 'The human subscribed to a music streaming service but is unable to play songs as it keeps saying they need to subscribe. The AI agent tries to help by connecting the human with a specialist to sort out the issue.\\n\\nThe human and the AI agent exchange information and try to troubleshoot the problem, with the AI agent asking for screenshots or details to help diagnose the issue. Despite their efforts, the problem persists, and the AI agent offers to connect the human with a specialist to further investigate and find a solution.',\n 'The human is looking to buy the Lego World bundle for £299, but it is currently out of stock. The AI agent apologizes and asks the human to provide more information, such as whether they want to buy online or in-store, and looks for an estimated back in stock date. The human is excited to hear that the issue with the website has been fixed and they will be able to order the bundle as normal the next day.\\n\\nIn summary, the human is interested in buying the Lego World bundle for £299, but it is currently out of stock, and the AI agent is helping the human to find out when it will be available again.',\n \"A human visited an AI agent's shop in Thika to purchase a Lip na Mpesa wristband but was sent to Annas Mall where they could not find the agent's team. The AI agent apologized and suggested checking with any M-PESA agent or Safaricom authorized dealer for assistance.\\n\\nThe human had previously visited the agent's shop in Thika but was told they were not sure where the team dealing with the wristbands was. The AI agent explained that the Mpesa 1 tap is currently being piloted in select towns, including Nairobi, Mombasa, Kisumu, Eldoret, and Nyeri, and the human can visit the nearest town to purchase one at a cost of 20/=.\",\n \"The human, Giselle, is frustrated with her bank's lack of compassion after speaking with a manager in the customer service department who refused to help her with her overdraft fees, despite her history of paying back the funds quickly. The AI agent responds by offering to review Giselle's account with her and provides a link for her to send her information.\"]"},"metadata":{}}]},{"cell_type":"code","source":"clean_trained_summaries(trained_model_summaries)\ntrained_model_summaries","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:31:34.073993Z","iopub.execute_input":"2024-08-19T22:31:34.074372Z","iopub.status.idle":"2024-08-19T22:31:34.080644Z","shell.execute_reply.started":"2024-08-19T22:31:34.074345Z","shell.execute_reply":"2024-08-19T22:31:34.079669Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"[\"Customer is complaining that he has subscribed to  and it isn't working. Agent updated that they will connect him with their play music specialist to sort this out.\",\n 'Customer is complaining about the new update iOS 11. Agent asks to send DM and they will work from there.',\n 'Customer is complaining that they have been charged $200+/month since then. Agent updated that they are seeing that this account was disconnected on 09/29/17.',\n 'Customer is complaining about the update that took 30+ minutes. Agent updated the URL to change the notification and action settings.',\n 'Customer is complaining about the poor customer service. Agent updated that they have escalated the support inquiry to a specialist and someone will be reaching out to them momentarily.',\n 'Customer is complaining that they are not able to get any help from customer services unless they are prepared to part with another £400 to get home with a disabled wife without changing trains. Agent updated that the only way to change it would be to pay for a change of journey.',\n \"Customer is complaining that he has subscribed to  and it isn't working. Agent updated that they will connect him with their play music specialist to sort this out.\",\n 'Customer is enquiring about the game. Agent updated that they have fixed the issue and it will take overnight for the website to update.',\n \"Customer is complaining that he was sent to Annas Mall where he didn't find the team. Agent updated that they can visit any authorized dealer or the other shops in town for one.\",\n \"Customer is complaining that even when someone tries their hardest to rectify the situation and you still don't have compassion. Agent updated that please let us know if you change your mind and would like us to review your account with you. We are here to help.\"]"},"metadata":{}}]},{"cell_type":"markdown","source":"<h1> Evaluating the Models </h1>","metadata":{}},{"cell_type":"markdown","source":"**We use the rouge metric from the evaluate library to evaluate the summaries**","metadata":{}},{"cell_type":"code","source":"import evaluate\n\nrouge_score = evaluate.load(\"rouge\") # We load the ROUGE metric from the evaluate libray, used to evaluate performance of NLP models","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:21:26.055495Z","iopub.execute_input":"2024-08-19T22:21:26.056436Z","iopub.status.idle":"2024-08-19T22:21:26.912954Z","shell.execute_reply.started":"2024-08-19T22:21:26.056397Z","shell.execute_reply":"2024-08-19T22:21:26.912038Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"455e243133294c1985a4f778efbe8d02"}},"metadata":{}}]},{"cell_type":"markdown","source":"**We create a function to preprocess the summaries text into the right format for ROUGE evaluation**","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import sent_tokenize\n\nimport nltk\n\n    \ndef compute_rouge_score(generated, reference):\n    #We need to add '\\n' to each line before send it to ROUGE\n    generated_with_newlines = [\"\\n\".join(sent_tokenize(s.strip())) for s in generated]\n    reference_with_newlines = [\"\\n\".join(sent_tokenize(s.strip())) for s in reference]\n    \n    return rouge_score.compute(\n        predictions=generated_with_newlines,\n        references=reference_with_newlines,\n        use_stemmer=True,\n    )","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:43:00.020576Z","iopub.execute_input":"2024-08-19T22:43:00.021311Z","iopub.status.idle":"2024-08-19T22:43:00.027054Z","shell.execute_reply.started":"2024-08-19T22:43:00.021281Z","shell.execute_reply":"2024-08-19T22:43:00.026155Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt_tab')","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:45:45.817081Z","iopub.execute_input":"2024-08-19T22:45:45.817471Z","iopub.status.idle":"2024-08-19T22:45:45.833910Z","shell.execute_reply.started":"2024-08-19T22:45:45.817444Z","shell.execute_reply":"2024-08-19T22:45:45.833099Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n","output_type":"stream"},{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"**We calculate the ROUGE score for the base model**","metadata":{}},{"cell_type":"code","source":"compute_rouge_score(trained_model_summaries, reference_summaries)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:45:50.970016Z","iopub.execute_input":"2024-08-19T22:45:50.970737Z","iopub.status.idle":"2024-08-19T22:45:51.247611Z","shell.execute_reply.started":"2024-08-19T22:45:50.970690Z","shell.execute_reply":"2024-08-19T22:45:51.246429Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"{'rouge1': 0.4674913373800669,\n 'rouge2': 0.2157533978391328,\n 'rougeL': 0.39614838302200645,\n 'rougeLsum': 0.43618860969167306}"},"metadata":{}}]},{"cell_type":"markdown","source":"**We calculate the ROUGE score for the fine-tuned model**","metadata":{}},{"cell_type":"code","source":"compute_rouge_score(base_model_summaries, reference_summaries)","metadata":{"execution":{"iopub.status.busy":"2024-08-19T22:46:39.369709Z","iopub.execute_input":"2024-08-19T22:46:39.370421Z","iopub.status.idle":"2024-08-19T22:46:39.667960Z","shell.execute_reply.started":"2024-08-19T22:46:39.370378Z","shell.execute_reply":"2024-08-19T22:46:39.667061Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"{'rouge1': 0.2879373375131953,\n 'rouge2': 0.07449206180843443,\n 'rougeL': 0.19704841133306294,\n 'rougeLsum': 0.2580567512209999}"},"metadata":{}}]},{"cell_type":"markdown","source":"The higher the ROUGE score for all metrics (Rouge1, Rouge2, RougeL, RougeLsum) the better the performance of the model in dialog summarization compared to the reference summaries in the dataset. The evaluation of the fine-tuned model should show higher ROUGE score than the base model when compared to the testing set summaries to prove that the training had an effect.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}